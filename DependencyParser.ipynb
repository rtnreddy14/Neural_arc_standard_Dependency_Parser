{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse_incr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyParsingDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = self.load_data(file_path)\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for sentence in parse_incr(file):\n",
    "                #print(sentence)\n",
    "                transitions = self.generate_transitions(sentence)\n",
    "                data.append(transitions)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def oracle(self, stack, buffer, sentence):\n",
    "        if len(stack)<2 :\n",
    "            return 'SHIFT'  # This ensures we don't try to access buffer[0] when buffer is empty\n",
    "        #print(stack,buffer)\n",
    "        top_of_stack = stack[-1] if stack else None\n",
    "        first_in_buffer = buffer[0] if buffer else None\n",
    "\n",
    "        if top_of_stack is not None and first_in_buffer is not None:\n",
    "            buffer_head_idx = sentence[first_in_buffer - 1]['head']  # Adjusting index for zero-based list access\n",
    "            stack_head_idx = sentence[top_of_stack - 1]['head']      # Adjusting index for zero-based list access\n",
    "\n",
    "            if buffer_head_idx == top_of_stack:\n",
    "                return 'RIGHT-ARC'\n",
    "            elif stack_head_idx == first_in_buffer:\n",
    "                return 'LEFT-ARC'\n",
    "\n",
    "        return 'SHIFT'\n",
    "    \n",
    "\n",
    "    def generate_transitions(self, sentence):\n",
    "        transitions = []\n",
    "        stack = [0]  # Start with ROOT at the stack\n",
    "\n",
    "\n",
    "            # Initialize buffer to handle multi-word tokens and null tokens\n",
    "        buffer = deque()\n",
    "        for token in sentence:\n",
    "            if isinstance(token['id'], tuple) and token['form'] == '-':\n",
    "                continue  # Ignore null tokens if represented by '-'\n",
    "            elif isinstance(token['id'], tuple):\n",
    "                buffer.append(token['id'][0])  # Use the first index from the tuple for multi-word tokens\n",
    "            else:\n",
    "                buffer.append(token['id'])\n",
    "\n",
    "    \n",
    "\n",
    "        arcs = []  #(dep,head)\n",
    "\n",
    "        while buffer:\n",
    "            action = self.oracle(stack, buffer, sentence)\n",
    "\n",
    "            features = self.extract_features(stack, buffer, sentence)\n",
    "            transitions.append((features, action))\n",
    "        \n",
    "        \n",
    "            if action == 'SHIFT':\n",
    "                stack.append(buffer.popleft())\n",
    "            elif action == 'LEFT-ARC':\n",
    "                arcs.append((stack[-1], buffer[0]))\n",
    "                stack.pop()\n",
    "            elif action == 'RIGHT-ARC' :\n",
    "                arcs.append((buffer[0], stack[-1]))\n",
    "                buffer.popleft()\n",
    "\n",
    "        return transitions\n",
    "\n",
    "    def extract_features(self, stack, buffer, sentence):\n",
    "    # Initialize default features\n",
    "        features = {\n",
    "        'stack_top_id': 0, 'buffer_first_id': 0,\n",
    "        'stack_top_word': 'NULL', 'buffer_first_word': 'NULL',\n",
    "        'stack_top_pos': 'NULL', 'buffer_first_pos': 'NULL'\n",
    "        }\n",
    "\n",
    "    # Check and assign the top of the stack features\n",
    "        if stack:\n",
    "            stack_top_idx = stack[-1]\n",
    "            stack_top_token = sentence[stack_top_idx - 1]  # Adjust for zero indexing\n",
    "            features['stack_top_id'] = stack_top_idx\n",
    "            features['stack_top_word'] = stack_top_token['form'].lower()\n",
    "            features['stack_top_pos'] = stack_top_token['upos']\n",
    "\n",
    "    # Check and assign the first item in the buffer features\n",
    "        if buffer:\n",
    "            buffer_first_idx = buffer[0]\n",
    "            buffer_first_token = sentence[buffer_first_idx - 1]  # Adjust for zero indexing\n",
    "            features['buffer_first_id'] = buffer_first_idx\n",
    "            features['buffer_first_word'] = buffer_first_token['form'].lower()\n",
    "            features['buffer_first_pos'] = buffer_first_token['upos']\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    # Retrieve the sentence data (list of tuples)\n",
    "        sentence_data = self.data[idx]\n",
    "    \n",
    "    # You might want to process each token in the sentence. \n",
    "    # Here's an example of how you could handle this:\n",
    "        processed_data = []\n",
    "        for token in sentence_data:\n",
    "            if len(token) == 2:\n",
    "                features, action = token\n",
    "                processed_data.append((features, action))\n",
    "            else:\n",
    "                raise ValueError(f\"Expected each token to be a tuple of 2 elements, got {len(token)} elements.\")\n",
    "    \n",
    "    # Return the processed list of tokens\n",
    "        return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DependencyParsingDataset('./UD_English-EWT-master/en_ewt-ud-train.conllu')\n",
    "dev_dataset = DependencyParsingDataset('./UD_English-EWT-master/en_ewt-ud-dev.conllu')\n",
    "test_dataset = DependencyParsingDataset('./UD_English-EWT-master/en_ewt-ud-test.conllu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyParserModel(nn.Module):\n",
    "    def __init__(self, pos_vocab_size, pos_embedding_dim, embedding_dim, hidden_dim, num_actions):\n",
    "        super(DependencyParserModel, self).__init__()\n",
    "        self.pos_embedding = nn.Embedding(pos_vocab_size, pos_embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim * 2 + pos_embedding_dim * 2, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_actions)\n",
    "\n",
    "    def forward(self, stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices):\n",
    "        # Embed POS tags and expand dimensions to match embeddings\n",
    "        stack_top_pos_embeddings = self.pos_embedding(stack_top_pos_indices).squeeze(1)\n",
    "        buffer_first_pos_embeddings = self.pos_embedding(buffer_first_pos_indices).squeeze(1)\n",
    "\n",
    "        # Combine all embeddings\n",
    "        combined_embeddings = torch.cat((stack_top_embeddings, buffer_first_embeddings, stack_top_pos_embeddings, buffer_first_pos_embeddings), dim=1)\n",
    "        \n",
    "        # Process with LSTM\n",
    "        lstm_out, _ = self.lstm(combined_embeddings.unsqueeze(1))  # Unsqueeze to add a seq_length dimension\n",
    "        logits = self.fc(lstm_out[:, -1, :])\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pos_vocab(dataset):\n",
    "    pos_tags = set()\n",
    "    for sentence_data in dataset:  # Iterate over each sentence data in the dataset\n",
    "        for token in sentence_data:  # Each token is a tuple (features, action)\n",
    "            features, action = token\n",
    "            # Assuming 'features' is a dictionary containing 'stack_top_pos' and 'buffer_first_pos'\n",
    "            pos_tags.add(features['stack_top_pos'])\n",
    "            pos_tags.add(features['buffer_first_pos'])\n",
    "\n",
    "    # Map each POS tag to a unique index\n",
    "    pos_to_index = {pos: idx for idx, pos in enumerate(pos_tags)}\n",
    "    pos_to_index['<PAD>'] = len(pos_to_index)  # Adding a padding token for POS tags\n",
    "    return pos_to_index\n",
    "\n",
    "# Assuming 'DependencyParsingDataset' can be iterated and yields (features, action)\n",
    "pos_vocab = build_pos_vocab(train_dataset)\n",
    "\n",
    "# Printing the vocabulary to verify\n",
    "# print(\"POS Tag Vocabulary:\", pos_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model directly from Gensim's API\n",
    "word2VecModel = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_word_embedding(word, word2VecModel):\n",
    "    try:\n",
    "        return word2VecModel[word]\n",
    "    except KeyError:\n",
    "        # Attempt to remove apostrophes and retry\n",
    "        word = word.replace(\"'\", \"\")\n",
    "        if word in word2VecModel:\n",
    "            return word2VecModel[word]\n",
    "        # Finally, return a zero vector if no suitable word is found\n",
    "        return np.zeros(word2VecModel.vector_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "action_to_index = {\n",
    "    \"SHIFT\": 0,\n",
    "    \"RIGHT-ARC\": 1,\n",
    "    \"LEFT-ARC\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def collate_fn(batch, word2VecModel, pos_vocab, action_to_index):\n",
    "    # Containers for batch data\n",
    "    stack_top_embeddings, buffer_first_embeddings = [], []\n",
    "    stack_top_pos_indices, buffer_first_pos_indices = [], []\n",
    "    actions_indices = []\n",
    "\n",
    "    for sentence in batch:\n",
    "        for features, action in sentence:\n",
    "            # Convert words to embeddings\n",
    "            stack_top_embedding = torch.tensor(get_word_embedding(features['stack_top_word'], word2VecModel), dtype=torch.float)\n",
    "            buffer_first_embedding = torch.tensor(get_word_embedding(features['buffer_first_word'], word2VecModel), dtype=torch.float)\n",
    "\n",
    "            # Convert POS tags to indices\n",
    "            stack_top_pos_index = pos_vocab[features['stack_top_pos']]\n",
    "            buffer_first_pos_index = pos_vocab[features['buffer_first_pos']]\n",
    "\n",
    "            # Append embeddings and POS indices separately\n",
    "            stack_top_embeddings.append(stack_top_embedding)\n",
    "            buffer_first_embeddings.append(buffer_first_embedding)\n",
    "            stack_top_pos_indices.append(torch.tensor([stack_top_pos_index], dtype=torch.long))\n",
    "            buffer_first_pos_indices.append(torch.tensor([buffer_first_pos_index], dtype=torch.long))\n",
    "\n",
    "            # Convert action to index and append\n",
    "            actions_indices.append(action_to_index[action])\n",
    "\n",
    "    # Pad sequences\n",
    "    stack_top_embeddings = pad_sequence(stack_top_embeddings, batch_first=True, padding_value=0.0)\n",
    "    buffer_first_embeddings = pad_sequence(buffer_first_embeddings, batch_first=True, padding_value=0.0)\n",
    "    stack_top_pos_indices = pad_sequence(stack_top_pos_indices, batch_first=True, padding_value=pos_vocab['<PAD>'])\n",
    "    buffer_first_pos_indices = pad_sequence(buffer_first_pos_indices, batch_first=True, padding_value=pos_vocab['<PAD>'])\n",
    "\n",
    "    actions_indices = torch.tensor(actions_indices, dtype=torch.long)\n",
    "\n",
    "    return (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataLoader usage\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_fn(batch, word2VecModel, pos_vocab, action_to_index))\n",
    "\n",
    "val_loader = DataLoader(dev_dataset, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_fn(batch, word2VecModel, pos_vocab, action_to_index))\n",
    "for batch in train_loader:\n",
    "    # Unpack the batch data\n",
    "    (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices = batch\n",
    "    \n",
    "    # Print shapes and type of data in the batch\n",
    "    print(\"Stack Top Embeddings Shape:\", stack_top_embeddings.shape)\n",
    "    print(\"Buffer First Embeddings Shape:\", buffer_first_embeddings.shape)\n",
    "    print(\"Stack Top POS Indices Shape:\", stack_top_pos_indices.shape)\n",
    "    print(\"Buffer First POS Indices Shape:\", buffer_first_pos_indices.shape)\n",
    "    print(\"Actions Indices Shape:\", actions_indices.shape)\n",
    "    print(\"Actions Indices:\", actions_indices)\n",
    "\n",
    "    # Optionally, break after the first batch to just see one example\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you've predefined the following variables\n",
    "pos_vocab_size = len(pos_vocab)  # from your POS vocabulary\n",
    "pos_embedding_dim = 50  # arbitrary choice, can be tuned\n",
    "embedding_dim = 300  # assuming your word embeddings are of size 300\n",
    "hidden_dim = 128  # hidden dimension of the LSTM\n",
    "num_actions = 3  # \"SHIFT\", \"RIGHT-ARC\", \"LEFT-ARC\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "model = DependencyParserModel(pos_vocab_size, pos_embedding_dim, embedding_dim, hidden_dim, num_actions)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss and optimizer\n",
    "num_epochs = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop for one epoch\n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices in train_loader:\n",
    "        # Move tensors to the appropriate device\n",
    "        stack_top_embeddings = stack_top_embeddings.to(device)\n",
    "        buffer_first_embeddings = buffer_first_embeddings.to(device)\n",
    "        stack_top_pos_indices = stack_top_pos_indices.to(device)\n",
    "        buffer_first_pos_indices = buffer_first_pos_indices.to(device)\n",
    "        actions_indices = actions_indices.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, actions_indices)\n",
    "\n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    precision = precision_score(true, predicted, average='weighted')\n",
    "    recall = recall_score(true, predicted, average='weighted')\n",
    "    f1 = f1_score(true, predicted, average='weighted')\n",
    "    return precision, recall, f1\n",
    "\n",
    "def validate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predicted = []\n",
    "    all_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices in data_loader:\n",
    "            stack_top_embeddings = stack_top_embeddings.to(device)\n",
    "            buffer_first_embeddings = buffer_first_embeddings.to(device)\n",
    "            stack_top_pos_indices = stack_top_pos_indices.to(device)\n",
    "            buffer_first_pos_indices = buffer_first_pos_indices.to(device)\n",
    "            actions_indices = actions_indices.to(device)\n",
    "\n",
    "            outputs = model(stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices)\n",
    "\n",
    "            loss = criterion(outputs, actions_indices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predicted.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(actions_indices.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    precision, recall, f1 = calculate_metrics(all_predicted, all_true)\n",
    "    return avg_loss, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_Hindi = DependencyParsingDataset('./UD_Hindi-HDTB-master/hi_hdtb-ud-train.conllu')\n",
    "dev_dataset_Hindi = DependencyParsingDataset('./UD_Hindi-HDTB-master/hi_hdtb-ud-dev.conllu')\n",
    "test_dataset_Hindi = DependencyParsingDataset('./UD_Hindi-HDTB-master/hi_hdtb-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Download the FastText Hindi word vectors from the FastText website\n",
    "# Ensure the file 'cc.hi.300.vec.gz' is in your current working directory\n",
    "\n",
    "# Load the FastText Hindi word vectors\n",
    "hindi_model_path = \"C:/Users/Rithin/Downloads/cc.hi.300.vec/cc.hi.300.vec\" # Path to the downloaded file\n",
    "hindi_word2vec_model = KeyedVectors.load_word2vec_format(hindi_model_path, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vocab = build_pos_vocab(train_dataset_Hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hindi = DependencyParserModel(pos_vocab_size, pos_embedding_dim, embedding_dim, hidden_dim, num_actions)\n",
    "model_hindi.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataLoader usage\n",
    "train_loader_hindi = DataLoader(train_dataset_Hindi, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_fn(batch, hindi_word2vec_model, pos_vocab, action_to_index))\n",
    "\n",
    "val_loader_hindi = DataLoader(dev_dataset_Hindi, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_fn(batch, hindi_word2vec_model, pos_vocab, action_to_index))\n",
    "\n",
    "\n",
    "for batch in train_loader_hindi:\n",
    "    # Unpack the batch data\n",
    "    (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices = batch\n",
    "    \n",
    "    # Print shapes and type of data in the batch\n",
    "    print(\"Stack Top Embeddings Shape:\", stack_top_embeddings.shape)\n",
    "    print(\"Buffer First Embeddings Shape:\", buffer_first_embeddings.shape)\n",
    "    print(\"Stack Top POS Indices Shape:\", stack_top_pos_indices.shape)\n",
    "    print(\"Buffer First POS Indices Shape:\", buffer_first_pos_indices.shape)\n",
    "    print(\"Actions Indices Shape:\", actions_indices.shape)\n",
    "    print(\"Actions Indices:\", actions_indices)\n",
    "\n",
    "    # Optionally, break after the first batch to just see one example\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs =14\n",
    "\n",
    "model_hindi.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices in train_loader_hindi:\n",
    "        # Move tensors to the appropriate device\n",
    "        stack_top_embeddings = stack_top_embeddings.to(device)\n",
    "        buffer_first_embeddings = buffer_first_embeddings.to(device)\n",
    "        stack_top_pos_indices = stack_top_pos_indices.to(device)\n",
    "        buffer_first_pos_indices = buffer_first_pos_indices.to(device)\n",
    "        actions_indices = actions_indices.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, actions_indices)\n",
    "\n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader_hindi)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    precision = precision_score(true, predicted, average='weighted')\n",
    "    recall = recall_score(true, predicted, average='weighted')\n",
    "    f1 = f1_score(true, predicted, average='weighted')\n",
    "    return precision, recall, f1\n",
    "\n",
    "def validate_model(model, data_loader, criterion, device):\n",
    "    model_hindi.eval()\n",
    "    total_loss = 0\n",
    "    all_predicted = []\n",
    "    all_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices), actions_indices in data_loader:\n",
    "            stack_top_embeddings = stack_top_embeddings.to(device)\n",
    "            buffer_first_embeddings = buffer_first_embeddings.to(device)\n",
    "            stack_top_pos_indices = stack_top_pos_indices.to(device)\n",
    "            buffer_first_pos_indices = buffer_first_pos_indices.to(device)\n",
    "            actions_indices = actions_indices.to(device)\n",
    "\n",
    "            outputs = model(stack_top_embeddings, buffer_first_embeddings, stack_top_pos_indices, buffer_first_pos_indices)\n",
    "\n",
    "            loss = criterion(outputs, actions_indices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predicted.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(actions_indices.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    precision, recall, f1 = calculate_metrics(all_predicted, all_true)\n",
    "    return avg_loss, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model on the validation data\n",
    "val_loss, val_precision, val_recall, val_f1 = validate_model(model_hindi, val_loader_hindi, criterion, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# Test the model on the test data\n",
    "test_loss, test_precision, test_recall, test_f1 = validate_model(model_hindi, test_loader_hindi, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
