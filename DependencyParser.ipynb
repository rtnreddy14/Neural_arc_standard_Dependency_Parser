{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse_incr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyParsingDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = self.load_data(file_path)\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for sentence in parse_incr(file):\n",
    "                #print(sentence)\n",
    "                transitions = self.generate_transitions(sentence)\n",
    "                data.append(transitions)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def oracle(self, stack, buffer, sentence):\n",
    "        if len(stack)<2 :\n",
    "            return 'SHIFT'  # This ensures we don't try to access buffer[0] when buffer is empty\n",
    "        #print(stack,buffer)\n",
    "        top_of_stack = stack[-1] if stack else None\n",
    "        first_in_buffer = buffer[0] if buffer else None\n",
    "\n",
    "        if top_of_stack is not None and first_in_buffer is not None:\n",
    "            buffer_head_idx = sentence[first_in_buffer - 1]['head']  # Adjusting index for zero-based list access\n",
    "            stack_head_idx = sentence[top_of_stack - 1]['head']      # Adjusting index for zero-based list access\n",
    "\n",
    "            if buffer_head_idx == top_of_stack:\n",
    "                return 'RIGHT-ARC'\n",
    "            elif stack_head_idx == first_in_buffer:\n",
    "                return 'LEFT-ARC'\n",
    "\n",
    "        return 'SHIFT'\n",
    "    \n",
    "\n",
    "    def generate_transitions(self, sentence):\n",
    "        transitions = []\n",
    "        stack = [0]  # Start with ROOT at the stack\n",
    "\n",
    "\n",
    "            # Initialize buffer to handle multi-word tokens and null tokens\n",
    "        buffer = deque()\n",
    "        for token in sentence:\n",
    "            if isinstance(token['id'], tuple) and token['form'] == '-':\n",
    "                continue  # Ignore null tokens if represented by '-'\n",
    "            elif isinstance(token['id'], tuple):\n",
    "                buffer.append(token['id'][0])  # Use the first index from the tuple for multi-word tokens\n",
    "            else:\n",
    "                buffer.append(token['id'])\n",
    "\n",
    "    \n",
    "\n",
    "        arcs = []  #(dep,head)\n",
    "\n",
    "        while buffer:\n",
    "            action = self.oracle(stack, buffer, sentence)\n",
    "\n",
    "            features = self.extract_features(stack, buffer, sentence)\n",
    "            transitions.append((features, action))\n",
    "        \n",
    "        \n",
    "            if action == 'SHIFT':\n",
    "                stack.append(buffer.popleft())\n",
    "            elif action == 'LEFT-ARC':\n",
    "                arcs.append((stack[-1], buffer[0]))\n",
    "                stack.pop()\n",
    "            elif action == 'RIGHT-ARC' :\n",
    "                arcs.append((buffer[0], stack[-1]))\n",
    "                buffer.popleft()\n",
    "\n",
    "        return transitions\n",
    "\n",
    "    def extract_features(self, stack, buffer, sentence):\n",
    "    # Initialize default features\n",
    "        features = {\n",
    "        'stack_top_id': 0, 'buffer_first_id': 0,\n",
    "        'stack_top_word': 'NULL', 'buffer_first_word': 'NULL',\n",
    "        'stack_top_pos': 'NULL', 'buffer_first_pos': 'NULL'\n",
    "        }\n",
    "\n",
    "    # Check and assign the top of the stack features\n",
    "        if stack:\n",
    "            stack_top_idx = stack[-1]\n",
    "            stack_top_token = sentence[stack_top_idx - 1]  # Adjust for zero indexing\n",
    "            features['stack_top_id'] = stack_top_idx\n",
    "            features['stack_top_word'] = stack_top_token['form'].lower()\n",
    "            features['stack_top_pos'] = stack_top_token['upos']\n",
    "\n",
    "    # Check and assign the first item in the buffer features\n",
    "        if buffer:\n",
    "            buffer_first_idx = buffer[0]\n",
    "            buffer_first_token = sentence[buffer_first_idx - 1]  # Adjust for zero indexing\n",
    "            features['buffer_first_id'] = buffer_first_idx\n",
    "            features['buffer_first_word'] = buffer_first_token['form'].lower()\n",
    "            features['buffer_first_pos'] = buffer_first_token['upos']\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    # Retrieve the sentence data (list of tuples)\n",
    "        sentence_data = self.data[idx]\n",
    "    \n",
    "    # You might want to process each token in the sentence. \n",
    "    # Here's an example of how you could handle this:\n",
    "        processed_data = []\n",
    "        for token in sentence_data:\n",
    "            if len(token) == 2:\n",
    "                features, action = token\n",
    "                processed_data.append((features, action))\n",
    "            else:\n",
    "                raise ValueError(f\"Expected each token to be a tuple of 2 elements, got {len(token)} elements.\")\n",
    "    \n",
    "    # Return the processed list of tokens\n",
    "        return processed_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
